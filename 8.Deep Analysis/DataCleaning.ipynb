{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a242b92a-581b-44eb-af37-905d0cb3eaf1",
   "metadata": {},
   "source": [
    "# Fuel Prices Analysis (United Kingdom Data)\n",
    "\n",
    "## Research Goals\n",
    "\n",
    "- Identify how fuel prices fluctuate over time and determine key patterns.\n",
    "- Analyze the impact of external factors such as supply chain disruptions, oil prices, VAT, inflation, and geopolitical events on fuel prices.\n",
    "- Compare fuel price trends across different time periods to understand long-term changes.\n",
    "- Use machine learning models to predict future fuel price movements based on historical data.\n",
    "- Store and process data efficiently using **AWS S3** and **Snowflake**, ensuring scalability and reliability.\n",
    "- Present findings through interactive **Power BI** dashboards and **Plotly Dash** visualizations for clear and actionable insights.\n",
    "- Implement a **deployment mode** for predictive models, allowing real-time or batch forecasting of fuel prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe9b38c-3360-45de-82dc-53c9951b0237",
   "metadata": {},
   "source": [
    "## 8. Deep Analysis: Next Steps\n",
    "\n",
    "### **Steps**\n",
    "1. **Data Validation & Cleaning**  \n",
    "   - Ensure all data is properly formatted and aligned for further analysis.\n",
    "   - Handle missing values and inconsistencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "228efb4e-5d7b-41de-818b-341c60175467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snowflake-connector-python in c:\\users\\zana\\miniconda3\\envs\\pymc_env\\lib\\site-packages (3.13.2)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in c:\\users\\zana\\miniconda3\\envs\\pymc_env\\lib\\site-packages (from snowflake-connector-python) (1.5.1)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in c:\\users\\zana\\miniconda3\\envs\\pymc_env\\lib\\site-packages (from snowflake-connector-python) (1.16.0)\n",
      "Requirement already satisfied: cryptography>=3.1.0 in c:\\users\\zana\\miniconda3\\envs\\pymc_env\\lib\\site-packages (from snowflake-connector-python) (44.0.0)\n",
      "Requirement already satisfied: pyOpenSSL<25.0.0,>=22.0.0 in c:\\users\\zana\\miniconda3\\envs\\pymc_env\\lib\\site-packages (from snowflake-connector-python) (24.3.0)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in c:\\users\\zana\\miniconda3\\envs\\pymc_env\\lib\\site-packages (from snowflake-connector-python) (2.10.1)\n",
      "Requirement already satisfied: pytz in c:\\users\\zana\\miniconda3\\envs\\pymc_env\\lib\\site-packages (from snowflake-connector-python) (2024.2)\n",
      "Requirement already satisfied: requests<3.0.0 in c:\\users\\zana\\miniconda3\\envs\\pymc_env\\lib\\site-packages (from snowflake-connector-python) (2.32.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\zana\\miniconda3\\envs\\pymc_env\\lib\\site-packages (from snowflake-connector-python) (24.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\zana\\miniconda3\\envs\\pymc_env\\lib\\site-packages (from snowflake-connector-python) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\zana\\miniconda3\\envs\\pymc_env\\lib\\site-packages (from snowflake-connector-python) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\zana\\miniconda3\\envs\\pymc_env\\lib\\site-packages (from snowflake-connector-python) (2024.8.30)\n",
      "Requirement already satisfied: typing_extensions<5,>=4.3 in c:\\users\\zana\\miniconda3\\envs\\pymc_env\\lib\\site-packages (from snowflake-connector-python) (4.12.2)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in c:\\users\\zana\\miniconda3\\envs\\pymc_env\\lib\\site-packages (from snowflake-connector-python) (3.16.0)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in c:\\users\\zana\\miniconda3\\envs\\pymc_env\\lib\\site-packages (from snowflake-connector-python) (2.4.0)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=2.6.0 in c:\\users\\zana\\miniconda3\\envs\\pymc_env\\lib\\site-packages (from snowflake-connector-python) (3.10.0)\n",
      "Requirement already satisfied: tomlkit in c:\\users\\zana\\miniconda3\\envs\\pymc_env\\lib\\site-packages (from snowflake-connector-python) (0.13.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\zana\\miniconda3\\envs\\pymc_env\\lib\\site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python) (2.21)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\zana\\miniconda3\\envs\\pymc_env\\lib\\site-packages (from requests<3.0.0->snowflake-connector-python) (2.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install snowflake-connector-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c2c0fe-ac2a-4a82-b661-b0bd4bd1bb48",
   "metadata": {},
   "source": [
    "#### 8.1 Snowflake connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b25b3a2-0926-4dbf-aa39-d969f1b1ef20",
   "metadata": {},
   "source": [
    "#### 8.2 Data Uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34f2beb9-503c-48cc-ac5e-c3f4ccf4c005",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create cursor to execute queries\n",
    "cursor = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78c09e17-0d0d-4618-ad13-77f5b73944df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DATE  ULSP_PRICE  ULSD_PRICE  ULSP_DUTY  ULSD_DUTY\n",
      "0  2019-01-07      1.2027      1.3033     0.5795     0.5795\n",
      "1  2019-01-14      1.1953      1.2947     0.5795     0.5795\n",
      "2  2019-01-21      1.1912      1.2892     0.5795     0.5795\n",
      "3  2019-01-28      1.1929      1.2910     0.5795     0.5795\n",
      "4  2019-02-04      1.1913      1.2913     0.5795     0.5795\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM fuel.fuel\"\n",
    "cursor.execute(query)\n",
    "\n",
    "# Fetch results and convert to pandas DataFrame\n",
    "import pandas as pd\n",
    "df_fuel = pd.DataFrame(cursor.fetchall(), columns=[col[0] for col in cursor.description])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_fuel.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeb71c2a-603c-4441-b3fa-1c43c6202c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DATE  PRICE\n",
      "0  2019-01-01  59.41\n",
      "1  2019-02-01  63.96\n",
      "2  2019-03-01  66.14\n",
      "3  2019-04-01  71.23\n",
      "4  2019-05-01  71.32\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM oil.oil\"  # You can adjust the query as needed\n",
    "cursor.execute(query)\n",
    "\n",
    "# Fetch results and convert to pandas DataFrame\n",
    "import pandas as pd\n",
    "df_oil = pd.DataFrame(cursor.fetchall(), columns=[col[0] for col in cursor.description])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_oil.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0934bf80-8d62-41bb-8efe-1a4860371640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DATE   PRICE    OPEN    HIGH     LOW  CHANGE_PERCENTAGE\n",
      "0  2024-12-31  1.2511  1.2548  1.2571  1.2504            -0.0032\n",
      "1  2024-12-30  1.2551  1.2571  1.2608  1.2505            -0.0022\n",
      "2  2024-12-27  1.2579  1.2523  1.2594  1.2503             0.0043\n",
      "3  2024-12-26  1.2525  1.2552  1.2553  1.2500            -0.0022\n",
      "4  2024-12-25  1.2553  1.2543  1.2560  1.2526             0.0009\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM currency.currency\"\n",
    "cursor.execute(query)\n",
    "\n",
    "# Fetch results and convert to pandas DataFrame\n",
    "import pandas as pd\n",
    "df_currency = pd.DataFrame(cursor.fetchall(), columns=[col[0] for col in cursor.description])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_currency.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c1f0d57-021a-437e-b4fe-b27b5a53745f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DATE  INFLATION_RATE\n",
      "0  2019-01-01             1.8\n",
      "1  2019-02-01             1.8\n",
      "2  2019-03-01             1.8\n",
      "3  2019-04-01             2.0\n",
      "4  2019-05-01             1.9\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM inflation.inflation LIMIT 10\"  # You can adjust the query as needed\n",
    "cursor.execute(query)\n",
    "\n",
    "# Fetch results and convert to pandas DataFrame\n",
    "import pandas as pd\n",
    "df_inflation = pd.DataFrame(cursor.fetchall(), columns=[col[0] for col in cursor.description])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_inflation.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e200e08-0f29-4a3a-bcb2-501f47cdcfa9",
   "metadata": {},
   "source": [
    "#### 8.3 Creating Base Date DataFrame\n",
    "\n",
    "##### **Objective**\n",
    "We need a complete date range from **2019-01-01 to 2024-12-31** to ensure that all datasets align properly.  \n",
    "Since different datasets have different date frequencies, this will serve as the foundation for merging.\n",
    "\n",
    "##### **Steps**\n",
    "1. Create a DataFrame (`df_base`) with all dates from **2019-01-01 to 2024-12-31**.\n",
    "2. Convert `DATE` to string format to match other datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb82cecc-04b5-433f-b065-621b6e3d0807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE    datetime64[ns]\n",
      "dtype: object\n",
      "        DATE\n",
      "0 2019-01-01\n",
      "1 2019-01-02\n",
      "2 2019-01-03\n",
      "3 2019-01-04\n",
      "4 2019-01-05\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a date range from 2019-01-01 to 2024-12-31\n",
    "date_range = pd.date_range(start=\"2019-01-01\", end=\"2024-12-31\", freq=\"D\")\n",
    "\n",
    "# Create a DataFrame with this date range\n",
    "df_base = pd.DataFrame(date_range, columns=[\"DATE\"])\n",
    "\n",
    "# Convert DATE to datetime format (even though it's already in datetime format after creation)\n",
    "df_base[\"DATE\"] = pd.to_datetime(df_base[\"DATE\"])\n",
    "\n",
    "# Verify the data type\n",
    "print(df_base.dtypes)\n",
    "print(df_base.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d8d3396-d17d-4664-a18e-46a99cca6146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE    datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030f4cdd-5b29-4531-8b7c-89e16414bd63",
   "metadata": {},
   "source": [
    "#### 8.4: Grouping and Structuring Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0f6cb96-ca4e-42e6-9cb9-d475e1a9fbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates in df_fuel: Empty DataFrame\n",
      "Columns: [DATE, ULSP_PRICE, ULSD_PRICE, ULSP_DUTY, ULSD_DUTY]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Convert DATE column to datetime format for consistency\n",
    "df_fuel[\"DATE\"] = pd.to_datetime(df_fuel[\"DATE\"])\n",
    "df_base[\"DATE\"] = pd.to_datetime(df_base[\"DATE\"])\n",
    "\n",
    "# Check for duplicate dates\n",
    "duplicates = df_fuel[df_fuel.duplicated(subset=[\"DATE\"], keep=False)]\n",
    "print(\"Duplicates in df_fuel:\", duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28d11398-6643-45b3-bcf0-14e795ce5259",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fuel = df_fuel.groupby(\"DATE\", as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99441c2d-a282-4f08-9732-adc7472fcb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        DATE  ULSP_PRICE  ULSD_PRICE  ULSP_DUTY  ULSD_DUTY\n",
      "0 2019-01-01         NaN         NaN        NaN        NaN\n",
      "1 2019-01-02         NaN         NaN        NaN        NaN\n",
      "2 2019-01-03         NaN         NaN        NaN        NaN\n",
      "3 2019-01-04         NaN         NaN        NaN        NaN\n",
      "4 2019-01-05         NaN         NaN        NaN        NaN\n",
      "DATE             0\n",
      "ULSP_PRICE    1879\n",
      "ULSD_PRICE    1879\n",
      "ULSP_DUTY     1879\n",
      "ULSD_DUTY     1879\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Merge df_fuel with df_base using a left join to retain all dates\n",
    "df_merged = df_base.merge(df_fuel, on=\"DATE\", how=\"left\")\n",
    "\n",
    "# Check the first few rows to verify\n",
    "print(df_merged.head())\n",
    "\n",
    "# Check for missing values after merging\n",
    "print(df_merged.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c058865-8f09-4297-8b6a-ec00006b1d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DATE  ULSP_PRICE  ULSD_PRICE  ULSP_DUTY  ULSD_DUTY\n",
      "0  2019-01-01         NaN         NaN        NaN        NaN\n",
      "1  2019-01-02         NaN         NaN        NaN        NaN\n",
      "2  2019-01-03         NaN         NaN        NaN        NaN\n",
      "3  2019-01-04         NaN         NaN        NaN        NaN\n",
      "4  2019-01-05         NaN         NaN        NaN        NaN\n",
      "5  2019-01-06         NaN         NaN        NaN        NaN\n",
      "6  2019-01-07      1.2027      1.3033     0.5795     0.5795\n",
      "7  2019-01-08         NaN         NaN        NaN        NaN\n",
      "8  2019-01-09         NaN         NaN        NaN        NaN\n",
      "9  2019-01-10         NaN         NaN        NaN        NaN\n",
      "10 2019-01-11         NaN         NaN        NaN        NaN\n",
      "11 2019-01-12         NaN         NaN        NaN        NaN\n",
      "12 2019-01-13         NaN         NaN        NaN        NaN\n",
      "13 2019-01-14      1.1953      1.2947     0.5795     0.5795\n",
      "14 2019-01-15         NaN         NaN        NaN        NaN\n",
      "15 2019-01-16         NaN         NaN        NaN        NaN\n",
      "16 2019-01-17         NaN         NaN        NaN        NaN\n",
      "17 2019-01-18         NaN         NaN        NaN        NaN\n",
      "18 2019-01-19         NaN         NaN        NaN        NaN\n",
      "19 2019-01-20         NaN         NaN        NaN        NaN\n"
     ]
    }
   ],
   "source": [
    "print(df_merged.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce3f460-5cb4-4963-a046-e2f63dc68cdd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f53d75c-9764-435a-8ba7-87354da0d286",
   "metadata": {},
   "source": [
    "#### 8.5 Merging Oil Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "adf39cdc-9e20-4d9d-a822-2968248a5b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DATE  ULSP_PRICE  ULSD_PRICE  ULSP_DUTY  ULSD_DUTY  PRICE\n",
      "0  2019-01-01         NaN         NaN        NaN        NaN  59.41\n",
      "1  2019-01-02         NaN         NaN        NaN        NaN    NaN\n",
      "2  2019-01-03         NaN         NaN        NaN        NaN    NaN\n",
      "3  2019-01-04         NaN         NaN        NaN        NaN    NaN\n",
      "4  2019-01-05         NaN         NaN        NaN        NaN    NaN\n",
      "5  2019-01-06         NaN         NaN        NaN        NaN    NaN\n",
      "6  2019-01-07      1.2027      1.3033     0.5795     0.5795    NaN\n",
      "7  2019-01-08         NaN         NaN        NaN        NaN    NaN\n",
      "8  2019-01-09         NaN         NaN        NaN        NaN    NaN\n",
      "9  2019-01-10         NaN         NaN        NaN        NaN    NaN\n",
      "10 2019-01-11         NaN         NaN        NaN        NaN    NaN\n",
      "11 2019-01-12         NaN         NaN        NaN        NaN    NaN\n",
      "12 2019-01-13         NaN         NaN        NaN        NaN    NaN\n",
      "13 2019-01-14      1.1953      1.2947     0.5795     0.5795    NaN\n",
      "14 2019-01-15         NaN         NaN        NaN        NaN    NaN\n",
      "15 2019-01-16         NaN         NaN        NaN        NaN    NaN\n",
      "16 2019-01-17         NaN         NaN        NaN        NaN    NaN\n",
      "17 2019-01-18         NaN         NaN        NaN        NaN    NaN\n",
      "18 2019-01-19         NaN         NaN        NaN        NaN    NaN\n",
      "19 2019-01-20         NaN         NaN        NaN        NaN    NaN\n"
     ]
    }
   ],
   "source": [
    "# Ensure DATE is in datetime format for consistency\n",
    "df_oil[\"DATE\"] = pd.to_datetime(df_oil[\"DATE\"])\n",
    "\n",
    "# Merge df_oil with df_merged using a left join\n",
    "df_merged = df_merged.merge(df_oil, on=\"DATE\", how=\"left\")\n",
    "\n",
    "# Display first 20 rows after merging df_oil\n",
    "print(df_merged.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12f7d74-c3ee-4c4b-9484-aad3327a58c1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f91b60-f4dd-491c-8315-810de67f82ae",
   "metadata": {},
   "source": [
    "#### 8.6 Merging Currency Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7d5f81f-265c-45d1-957b-ba45c67c7a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DATE  ULSP_PRICE  ULSD_PRICE  ULSP_DUTY  ULSD_DUTY  PRICE_x  PRICE_y  \\\n",
      "0  2019-01-01         NaN         NaN        NaN        NaN    59.41   1.2751   \n",
      "1  2019-01-02         NaN         NaN        NaN        NaN      NaN   1.2607   \n",
      "2  2019-01-03         NaN         NaN        NaN        NaN      NaN   1.2631   \n",
      "3  2019-01-04         NaN         NaN        NaN        NaN      NaN   1.2726   \n",
      "4  2019-01-05         NaN         NaN        NaN        NaN      NaN      NaN   \n",
      "5  2019-01-06         NaN         NaN        NaN        NaN      NaN      NaN   \n",
      "6  2019-01-07      1.2027      1.3033     0.5795     0.5795      NaN   1.2778   \n",
      "7  2019-01-08         NaN         NaN        NaN        NaN      NaN   1.2717   \n",
      "8  2019-01-09         NaN         NaN        NaN        NaN      NaN   1.2788   \n",
      "9  2019-01-10         NaN         NaN        NaN        NaN      NaN   1.2747   \n",
      "10 2019-01-11         NaN         NaN        NaN        NaN      NaN   1.2841   \n",
      "11 2019-01-12         NaN         NaN        NaN        NaN      NaN      NaN   \n",
      "12 2019-01-13         NaN         NaN        NaN        NaN      NaN      NaN   \n",
      "13 2019-01-14      1.1953      1.2947     0.5795     0.5795      NaN   1.2863   \n",
      "14 2019-01-15         NaN         NaN        NaN        NaN      NaN   1.2858   \n",
      "15 2019-01-16         NaN         NaN        NaN        NaN      NaN   1.2881   \n",
      "16 2019-01-17         NaN         NaN        NaN        NaN      NaN   1.2984   \n",
      "17 2019-01-18         NaN         NaN        NaN        NaN      NaN   1.2873   \n",
      "18 2019-01-19         NaN         NaN        NaN        NaN      NaN      NaN   \n",
      "19 2019-01-20         NaN         NaN        NaN        NaN      NaN      NaN   \n",
      "\n",
      "      OPEN    HIGH     LOW  CHANGE_PERCENTAGE  \n",
      "0   1.2761  1.2765  1.2725            -0.0005  \n",
      "1   1.2742  1.2776  1.2581            -0.0113  \n",
      "2   1.2605  1.2649  1.2439             0.0019  \n",
      "3   1.2629  1.2746  1.2616             0.0075  \n",
      "4      NaN     NaN     NaN                NaN  \n",
      "5      NaN     NaN     NaN                NaN  \n",
      "6   1.2730  1.2788  1.2717             0.0041  \n",
      "7   1.2780  1.2798  1.2706            -0.0048  \n",
      "8   1.2717  1.2805  1.2711             0.0056  \n",
      "9   1.2789  1.2803  1.2727            -0.0032  \n",
      "10  1.2758  1.2867  1.2710             0.0074  \n",
      "11     NaN     NaN     NaN                NaN  \n",
      "12     NaN     NaN     NaN                NaN  \n",
      "13  1.2848  1.2931  1.2817             0.0017  \n",
      "14  1.2862  1.2917  1.2670            -0.0004  \n",
      "15  1.2860  1.2898  1.2824             0.0018  \n",
      "16  1.2885  1.3002  1.2832             0.0080  \n",
      "17  1.2986  1.2995  1.2856            -0.0085  \n",
      "18     NaN     NaN     NaN                NaN  \n",
      "19     NaN     NaN     NaN                NaN  \n"
     ]
    }
   ],
   "source": [
    "# Ensure DATE is in datetime format for consistency\n",
    "df_currency[\"DATE\"] = pd.to_datetime(df_currency[\"DATE\"])\n",
    "\n",
    "# Merge df_currency with df_merged using a left join\n",
    "df_merged = df_merged.merge(df_currency, on=\"DATE\", how=\"left\")\n",
    "\n",
    "# Display first 20 rows after merging df_currency\n",
    "print(df_merged.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537061bf-6ca5-44a8-a138-a9d52f447efd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921a9bd4-4b6b-4826-a59d-5e1a84d87a79",
   "metadata": {},
   "source": [
    "#### 8.7 Drop Unnecessary Columns from Currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dace2ea6-2f41-4157-b5b1-d9822213a552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DATE  ULSP_PRICE  ULSD_PRICE  ULSP_DUTY  ULSD_DUTY  PRICE_OIL  \\\n",
      "0  2019-01-01         NaN         NaN        NaN        NaN      59.41   \n",
      "1  2019-01-02         NaN         NaN        NaN        NaN        NaN   \n",
      "2  2019-01-03         NaN         NaN        NaN        NaN        NaN   \n",
      "3  2019-01-04         NaN         NaN        NaN        NaN        NaN   \n",
      "4  2019-01-05         NaN         NaN        NaN        NaN        NaN   \n",
      "5  2019-01-06         NaN         NaN        NaN        NaN        NaN   \n",
      "6  2019-01-07      1.2027      1.3033     0.5795     0.5795        NaN   \n",
      "7  2019-01-08         NaN         NaN        NaN        NaN        NaN   \n",
      "8  2019-01-09         NaN         NaN        NaN        NaN        NaN   \n",
      "9  2019-01-10         NaN         NaN        NaN        NaN        NaN   \n",
      "10 2019-01-11         NaN         NaN        NaN        NaN        NaN   \n",
      "11 2019-01-12         NaN         NaN        NaN        NaN        NaN   \n",
      "12 2019-01-13         NaN         NaN        NaN        NaN        NaN   \n",
      "13 2019-01-14      1.1953      1.2947     0.5795     0.5795        NaN   \n",
      "14 2019-01-15         NaN         NaN        NaN        NaN        NaN   \n",
      "15 2019-01-16         NaN         NaN        NaN        NaN        NaN   \n",
      "16 2019-01-17         NaN         NaN        NaN        NaN        NaN   \n",
      "17 2019-01-18         NaN         NaN        NaN        NaN        NaN   \n",
      "18 2019-01-19         NaN         NaN        NaN        NaN        NaN   \n",
      "19 2019-01-20         NaN         NaN        NaN        NaN        NaN   \n",
      "\n",
      "    PRICE_CURRENCY  \n",
      "0           1.2751  \n",
      "1           1.2607  \n",
      "2           1.2631  \n",
      "3           1.2726  \n",
      "4              NaN  \n",
      "5              NaN  \n",
      "6           1.2778  \n",
      "7           1.2717  \n",
      "8           1.2788  \n",
      "9           1.2747  \n",
      "10          1.2841  \n",
      "11             NaN  \n",
      "12             NaN  \n",
      "13          1.2863  \n",
      "14          1.2858  \n",
      "15          1.2881  \n",
      "16          1.2984  \n",
      "17          1.2873  \n",
      "18             NaN  \n",
      "19             NaN  \n"
     ]
    }
   ],
   "source": [
    "# Keep only the PRICE column from df_currency\n",
    "df_merged = df_merged.drop(columns=[\"OPEN\", \"HIGH\", \"LOW\", \"CHANGE_PERCENTAGE\"])\n",
    "\n",
    "# Rename PRICE_y to PRICE_CURRENCY for clarity\n",
    "df_merged = df_merged.rename(columns={\"PRICE_y\": \"PRICE_CURRENCY\", \"PRICE_x\": \"PRICE_OIL\"})\n",
    "\n",
    "# Display first 20 rows to verify\n",
    "print(df_merged.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53987ce-407b-44c0-bd4c-0faa4e6d9f26",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4cc7ca-fd4d-4dc0-bdf6-a3ce97dfedae",
   "metadata": {},
   "source": [
    "#### 8.8 Merging Inflation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbe20c57-d9d1-45a3-94c5-150cc70cac82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DATE  ULSP_PRICE  ULSD_PRICE  ULSP_DUTY  ULSD_DUTY  PRICE_OIL  \\\n",
      "0  2019-01-01         NaN         NaN        NaN        NaN      59.41   \n",
      "1  2019-01-02         NaN         NaN        NaN        NaN        NaN   \n",
      "2  2019-01-03         NaN         NaN        NaN        NaN        NaN   \n",
      "3  2019-01-04         NaN         NaN        NaN        NaN        NaN   \n",
      "4  2019-01-05         NaN         NaN        NaN        NaN        NaN   \n",
      "5  2019-01-06         NaN         NaN        NaN        NaN        NaN   \n",
      "6  2019-01-07      1.2027      1.3033     0.5795     0.5795        NaN   \n",
      "7  2019-01-08         NaN         NaN        NaN        NaN        NaN   \n",
      "8  2019-01-09         NaN         NaN        NaN        NaN        NaN   \n",
      "9  2019-01-10         NaN         NaN        NaN        NaN        NaN   \n",
      "10 2019-01-11         NaN         NaN        NaN        NaN        NaN   \n",
      "11 2019-01-12         NaN         NaN        NaN        NaN        NaN   \n",
      "12 2019-01-13         NaN         NaN        NaN        NaN        NaN   \n",
      "13 2019-01-14      1.1953      1.2947     0.5795     0.5795        NaN   \n",
      "14 2019-01-15         NaN         NaN        NaN        NaN        NaN   \n",
      "15 2019-01-16         NaN         NaN        NaN        NaN        NaN   \n",
      "16 2019-01-17         NaN         NaN        NaN        NaN        NaN   \n",
      "17 2019-01-18         NaN         NaN        NaN        NaN        NaN   \n",
      "18 2019-01-19         NaN         NaN        NaN        NaN        NaN   \n",
      "19 2019-01-20         NaN         NaN        NaN        NaN        NaN   \n",
      "\n",
      "    PRICE_CURRENCY  INFLATION_RATE  \n",
      "0           1.2751             1.8  \n",
      "1           1.2607             NaN  \n",
      "2           1.2631             NaN  \n",
      "3           1.2726             NaN  \n",
      "4              NaN             NaN  \n",
      "5              NaN             NaN  \n",
      "6           1.2778             NaN  \n",
      "7           1.2717             NaN  \n",
      "8           1.2788             NaN  \n",
      "9           1.2747             NaN  \n",
      "10          1.2841             NaN  \n",
      "11             NaN             NaN  \n",
      "12             NaN             NaN  \n",
      "13          1.2863             NaN  \n",
      "14          1.2858             NaN  \n",
      "15          1.2881             NaN  \n",
      "16          1.2984             NaN  \n",
      "17          1.2873             NaN  \n",
      "18             NaN             NaN  \n",
      "19             NaN             NaN  \n"
     ]
    }
   ],
   "source": [
    "# Ensure DATE is in datetime format for consistency\n",
    "df_inflation[\"DATE\"] = pd.to_datetime(df_inflation[\"DATE\"])\n",
    "\n",
    "# Merge df_inflation with df_merged using a left join\n",
    "df_merged = df_merged.merge(df_inflation, on=\"DATE\", how=\"left\")\n",
    "\n",
    "# Display first 20 rows after merging df_inflation\n",
    "print(df_merged.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e3f148c-a4f4-489e-ae03-16d41ef6b818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved: merged_data_before_cleaning.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the merged DataFrame to CSV before cleaning\n",
    "df_merged.to_csv(\"merged_data_before_cleaning.csv\", index=False)\n",
    "\n",
    "# Verify that the file was saved correctly\n",
    "print(\"File saved: merged_data_before_cleaning.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec83518-8fdc-4714-85f5-6994d531da5c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133efdbe-be10-4ec2-9560-e9fa7b189c9f",
   "metadata": {},
   "source": [
    "####  Step 8.9: Filling Missing Values\n",
    "To ensure smooth analysis and avoid gaps, we use **forward fill (`ffill`)**, which replaces `NaN` values with the **last known** value.\n",
    "\n",
    "#### **Filling Strategy**\n",
    "1. **Forward fill (`ffill`)** – Each missing value is replaced by the previous available value.\n",
    "2. **If the first rows are missing values**, they remain `NaN` (we may apply `bfill` later if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2634a592-7517-4908-99c0-c2b61d0b9d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DATE  ULSP_PRICE  ULSD_PRICE  ULSP_DUTY  ULSD_DUTY  PRICE_OIL  \\\n",
      "0  2019-01-01         NaN         NaN        NaN        NaN      59.41   \n",
      "1  2019-01-02         NaN         NaN        NaN        NaN      59.41   \n",
      "2  2019-01-03         NaN         NaN        NaN        NaN      59.41   \n",
      "3  2019-01-04         NaN         NaN        NaN        NaN      59.41   \n",
      "4  2019-01-05         NaN         NaN        NaN        NaN      59.41   \n",
      "5  2019-01-06         NaN         NaN        NaN        NaN      59.41   \n",
      "6  2019-01-07      1.2027      1.3033     0.5795     0.5795      59.41   \n",
      "7  2019-01-08      1.2027      1.3033     0.5795     0.5795      59.41   \n",
      "8  2019-01-09      1.2027      1.3033     0.5795     0.5795      59.41   \n",
      "9  2019-01-10      1.2027      1.3033     0.5795     0.5795      59.41   \n",
      "10 2019-01-11      1.2027      1.3033     0.5795     0.5795      59.41   \n",
      "11 2019-01-12      1.2027      1.3033     0.5795     0.5795      59.41   \n",
      "12 2019-01-13      1.2027      1.3033     0.5795     0.5795      59.41   \n",
      "13 2019-01-14      1.1953      1.2947     0.5795     0.5795      59.41   \n",
      "14 2019-01-15      1.1953      1.2947     0.5795     0.5795      59.41   \n",
      "15 2019-01-16      1.1953      1.2947     0.5795     0.5795      59.41   \n",
      "16 2019-01-17      1.1953      1.2947     0.5795     0.5795      59.41   \n",
      "17 2019-01-18      1.1953      1.2947     0.5795     0.5795      59.41   \n",
      "18 2019-01-19      1.1953      1.2947     0.5795     0.5795      59.41   \n",
      "19 2019-01-20      1.1953      1.2947     0.5795     0.5795      59.41   \n",
      "\n",
      "    PRICE_CURRENCY  INFLATION_RATE  \n",
      "0           1.2751             1.8  \n",
      "1           1.2607             1.8  \n",
      "2           1.2631             1.8  \n",
      "3           1.2726             1.8  \n",
      "4           1.2726             1.8  \n",
      "5           1.2726             1.8  \n",
      "6           1.2778             1.8  \n",
      "7           1.2717             1.8  \n",
      "8           1.2788             1.8  \n",
      "9           1.2747             1.8  \n",
      "10          1.2841             1.8  \n",
      "11          1.2841             1.8  \n",
      "12          1.2841             1.8  \n",
      "13          1.2863             1.8  \n",
      "14          1.2858             1.8  \n",
      "15          1.2881             1.8  \n",
      "16          1.2984             1.8  \n",
      "17          1.2873             1.8  \n",
      "18          1.2873             1.8  \n",
      "19          1.2873             1.8  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zana\\AppData\\Local\\Temp\\ipykernel_1508\\1667416341.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_merged.fillna(method=\"ffill\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values using forward fill (ffill)\n",
    "df_merged.fillna(method=\"ffill\", inplace=True)\n",
    "\n",
    "# Display first 20 rows to verify\n",
    "print(df_merged.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8b8487d-40db-444f-9be9-9eba7acfd1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DATE  ULSP_PRICE  ULSD_PRICE  ULSP_DUTY  ULSD_DUTY  PRICE_OIL  \\\n",
      "0  2019-01-01         NaN         NaN        NaN        NaN      59.41   \n",
      "1  2019-01-02         NaN         NaN        NaN        NaN      59.41   \n",
      "2  2019-01-03         NaN         NaN        NaN        NaN      59.41   \n",
      "3  2019-01-04         NaN         NaN        NaN        NaN      59.41   \n",
      "4  2019-01-05         NaN         NaN        NaN        NaN      59.41   \n",
      "5  2019-01-06         NaN         NaN        NaN        NaN      59.41   \n",
      "6  2019-01-07      1.2027      1.3033     0.5795     0.5795      59.41   \n",
      "7  2019-01-08      1.2027      1.3033     0.5795     0.5795      59.41   \n",
      "8  2019-01-09      1.2027      1.3033     0.5795     0.5795      59.41   \n",
      "9  2019-01-10      1.2027      1.3033     0.5795     0.5795      59.41   \n",
      "10 2019-01-11      1.2027      1.3033     0.5795     0.5795      59.41   \n",
      "11 2019-01-12      1.2027      1.3033     0.5795     0.5795      59.41   \n",
      "12 2019-01-13      1.2027      1.3033     0.5795     0.5795      59.41   \n",
      "13 2019-01-14      1.1953      1.2947     0.5795     0.5795      59.41   \n",
      "14 2019-01-15      1.1953      1.2947     0.5795     0.5795      59.41   \n",
      "15 2019-01-16      1.1953      1.2947     0.5795     0.5795      59.41   \n",
      "16 2019-01-17      1.1953      1.2947     0.5795     0.5795      59.41   \n",
      "17 2019-01-18      1.1953      1.2947     0.5795     0.5795      59.41   \n",
      "18 2019-01-19      1.1953      1.2947     0.5795     0.5795      59.41   \n",
      "19 2019-01-20      1.1953      1.2947     0.5795     0.5795      59.41   \n",
      "\n",
      "    PRICE_CURRENCY  INFLATION_RATE  \n",
      "0           1.2751             1.8  \n",
      "1           1.2607             1.8  \n",
      "2           1.2631             1.8  \n",
      "3           1.2726             1.8  \n",
      "4           1.2726             1.8  \n",
      "5           1.2726             1.8  \n",
      "6           1.2778             1.8  \n",
      "7           1.2717             1.8  \n",
      "8           1.2788             1.8  \n",
      "9           1.2747             1.8  \n",
      "10          1.2841             1.8  \n",
      "11          1.2841             1.8  \n",
      "12          1.2841             1.8  \n",
      "13          1.2863             1.8  \n",
      "14          1.2858             1.8  \n",
      "15          1.2881             1.8  \n",
      "16          1.2984             1.8  \n",
      "17          1.2873             1.8  \n",
      "18          1.2873             1.8  \n",
      "19          1.2873             1.8  \n"
     ]
    }
   ],
   "source": [
    "# Use forward fill correctly\n",
    "df_merged.ffill(inplace=True)\n",
    "\n",
    "# Display first 20 rows to verify\n",
    "print(df_merged.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed2b9b7-fdbe-43d5-96f5-b171a9505530",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c18b6b6-3c50-4ed7-a78f-7981a210a079",
   "metadata": {},
   "source": [
    "#### 8.10 Apply Backward Fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f9d2ab7-71e0-4c12-81d9-1a10b90c03a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DATE  ULSP_PRICE  ULSD_PRICE  ULSP_DUTY  ULSD_DUTY  PRICE_OIL  \\\n",
      "0  2019-01-01      1.2027      1.3033     0.5795     0.5795      59.41   \n",
      "1  2019-01-02      1.2027      1.3033     0.5795     0.5795      59.41   \n",
      "2  2019-01-03      1.2027      1.3033     0.5795     0.5795      59.41   \n",
      "3  2019-01-04      1.2027      1.3033     0.5795     0.5795      59.41   \n",
      "4  2019-01-05      1.2027      1.3033     0.5795     0.5795      59.41   \n",
      "5  2019-01-06      1.2027      1.3033     0.5795     0.5795      59.41   \n",
      "6  2019-01-07      1.2027      1.3033     0.5795     0.5795      59.41   \n",
      "7  2019-01-08      1.2027      1.3033     0.5795     0.5795      59.41   \n",
      "8  2019-01-09      1.2027      1.3033     0.5795     0.5795      59.41   \n",
      "9  2019-01-10      1.2027      1.3033     0.5795     0.5795      59.41   \n",
      "10 2019-01-11      1.2027      1.3033     0.5795     0.5795      59.41   \n",
      "11 2019-01-12      1.2027      1.3033     0.5795     0.5795      59.41   \n",
      "12 2019-01-13      1.2027      1.3033     0.5795     0.5795      59.41   \n",
      "13 2019-01-14      1.1953      1.2947     0.5795     0.5795      59.41   \n",
      "14 2019-01-15      1.1953      1.2947     0.5795     0.5795      59.41   \n",
      "15 2019-01-16      1.1953      1.2947     0.5795     0.5795      59.41   \n",
      "16 2019-01-17      1.1953      1.2947     0.5795     0.5795      59.41   \n",
      "17 2019-01-18      1.1953      1.2947     0.5795     0.5795      59.41   \n",
      "18 2019-01-19      1.1953      1.2947     0.5795     0.5795      59.41   \n",
      "19 2019-01-20      1.1953      1.2947     0.5795     0.5795      59.41   \n",
      "\n",
      "    PRICE_CURRENCY  INFLATION_RATE  \n",
      "0           1.2751             1.8  \n",
      "1           1.2607             1.8  \n",
      "2           1.2631             1.8  \n",
      "3           1.2726             1.8  \n",
      "4           1.2726             1.8  \n",
      "5           1.2726             1.8  \n",
      "6           1.2778             1.8  \n",
      "7           1.2717             1.8  \n",
      "8           1.2788             1.8  \n",
      "9           1.2747             1.8  \n",
      "10          1.2841             1.8  \n",
      "11          1.2841             1.8  \n",
      "12          1.2841             1.8  \n",
      "13          1.2863             1.8  \n",
      "14          1.2858             1.8  \n",
      "15          1.2881             1.8  \n",
      "16          1.2984             1.8  \n",
      "17          1.2873             1.8  \n",
      "18          1.2873             1.8  \n",
      "19          1.2873             1.8  \n"
     ]
    }
   ],
   "source": [
    "# Apply backward fill (bfill) to fill remaining NaN values\n",
    "df_merged.bfill(inplace=True)\n",
    "\n",
    "# Display first 20 rows to verify\n",
    "print(df_merged.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "abdbf50a-8a7e-4888-88fb-57c6420ee73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved: final_cleaned_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned dataset to CSV\n",
    "df_merged.to_csv(\"final_cleaned_data.csv\", index=False)\n",
    "\n",
    "# Confirm that the file was saved\n",
    "print(\"File saved: final_cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee2df12-19b1-4d90-b322-f9c7461e1c88",
   "metadata": {},
   "source": [
    "### Completed Steps: Data Cleaning & Preparation\n",
    "\n",
    "#### 1. Data Collection & Merging\n",
    "- Extracted **fuel prices, oil prices, currency exchange rates, and inflation data**.\n",
    "- Merged all datasets into a **single DataFrame** with a complete date range.\n",
    "\n",
    "#### 2. Handling Missing Values\n",
    "- Applied **forward fill (ffill)** to propagate last known values.\n",
    "- Applied **backward fill (bfill)** to ensure all missing values were replaced.\n",
    "\n",
    "#### 3. Column Standardization & Renaming\n",
    "- Renamed columns for clarity:\n",
    "  - `\"PRICE_x\"` → `\"PRICE_OIL\"`\n",
    "  - `\"PRICE_y\"` → `\"PRICE_CURRENCY\"`\n",
    "- Dropped unnecessary columns (e.g., `\"OPEN\"`, `\"HIGH\"`, `\"LOW\"`, `\"CHANGE_PERCENTAGE\"` from currency data).\n",
    "\n",
    "#### 4. Data Cleaning Validation\n",
    "- Ensured **date consistency** across all datasets.\n",
    "- Verified **no duplicate values**.\n",
    "- Checked for **remaining NaN values** after filling.\n",
    "\n",
    "#### 5. Data Storage\n",
    "- Saved the final cleaned dataset as **`final_cleaned_data.csv`**.\n",
    "- Ready for **Exploratory Data Analysis (EDA)**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d2ad19-4de5-43d1-8ca9-0b10d0aa3753",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
